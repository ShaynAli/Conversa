function T = cnv_eval(varargin);
% function T = cnv_eval(pid,cam,targetFields,algorithms,varargin);
% Evaluates learning algorithms on a set of learning algorithms
% Returns a crossvalidated accuracy
% INPUT (VARARGIN):
%       'pid': Vector of PIDs to consider
%       'cam': Vector (same lenght) of cameras
%       'targetField': target field ('smile','talk',etc)
%       'algorithms': Cell array of algorithms
%           Each algorithm <alg> name must be accompanied by a
%           Matlab script with the prefix cnv_learn_<alg> and
%           cnv_predict_<alg> for learning and prediction
%       'plot',{fields}: For each test set, plot set of predictors, truth and
%           prediction. You need to give ot some variables to plot
% VARARGIN:
%       'crossval',
%               'within': 5-way split within each person
%               'between': between person (leave-one-out) classification
%
% OUTPUT:
%       T: Data frame of evalation
%
% By joern Diedrichsen & Shayaan Syed Ali

pid  =[1001;1005;1005]; % ;2001;2001;2002;2002;2006;2006;2024;2024];
cam  =[2;1;2]; % ;1;2;1;2;1;2;1;2];

nParts = 5;            % Number of partitions for within-person classification
crossval = 'between';  % Between is between person classification
lossfcn  = 'error';    % Loss function
verbose  = 1;
targetField = 'smile';
algorithms = {'logistic','logistic','csvm','csvm','null'};
options  = {{'fields',{'smile_l','smile_r'}},...
            {'fields',{'smile_l','smile_r','eye_closed_l','eye_closed_r'}},...
            {'fields',{'smile_l','smile_r'}},...
            {'fields',{'smile_l','smile_r','eye_closed_l','eye_closed_r'}},...
            {}};         % Additional options for algorithm
plotPred = {};
vararginoptions(varargin);

nAlgos = length(algorithms);
if (length(options)<nAlgos)
    options{nAlgos}={};
end;

% Get Data
if (verbose)
    fprintf('Loading data...\n');
end;
nData = length(pid);
Data =[];
for i=1:nData
    D=cnv_loadData(pid(i),cam(i));
    v= ones(length(D.timestamp),1);
    D.dataset = v*i;
    D.pid = v*pid(i);
    D.cam = v*cam(i);
    Data = addstruct(Data,D);
end;

% Set learning and prediction function handels
if ischar(algorithms)
    algorithms={algorithms};
end;
for i = 1:nAlgos
    % Set learning function
    learnFcn{i} = strcat('cnv_learn_', algorithms{i});
    predictFcn{i} = strcat('cnv_predict_', algorithms{i});
end;

% Now do crossvalidation in two different ways
T=[];
D=[];
switch (crossval)
    case 'between'
        
        % Remove the targetField from the data to prevent cheating!
        Labels = Data.(targetField);
        Data = rmfield(Data,targetField);
        
        % Now leave one data set out at a time
        for i=1:nData
            trainIndx = Data.dataset~=i;
            testIndx  = Data.dataset==i;
            prediction = zeros(sum(testIndx),nAlgos); 
            for m=1:nAlgos
                if (verbose)
                    fprintf('Data set %d %d, algorithm %s\n',pid(i),cam(i),algorithms{m});
                end;
                D.dataset = i; 
                D.algorithmNum = m;
                D.algorithm = algorithms(m);
                D.pid   = pid(i);
                D.cam   = cam(i);
                D.target  = {targetField};
                M = feval(learnFcn{m},getrow(Data,trainIndx),Labels(trainIndx,1),options{m}{:});
                prediction(:,m) = feval(predictFcn{m},M,getrow(Data,testIndx));
                D.meanPred = mean(prediction(:,m));
                D.propPred = mean(prediction(:,m)>0.5);
                D.propData = mean(Labels(testIndx,1));
                D.loss = evalLoss(Labels(testIndx,1),prediction(:,m),lossfcn);   % Calculate Loss
                T=addstruct(T,D);
            end;
            if (~isempty(plotPred))
                testData = getrow(Data,testIndx);
                time=Data.timestamp(testIndx,1); 
                subplot(nAlgos+1,1,1);
                X=[]; 
                for j=1:length(plotPred)
                    X=[X testData.(plotPred{j})];
                end;
                plot(time,X);
                l=legend(plotPred);
                set(l,'interpreter','none'); % Prevents interpretation of underscores as subscripts in legends
                title('data');
                cnv_drawPatches(time,Labels(testIndx,1),'k');
                for m=1:nAlgos
                    subplot(nAlgos+1,1,1+m);
                    plot(time,prediction(:,m));
                    cnv_drawPatches(time,prediction(:,m)>0.5,'k');
                    title(sprintf('%s: %2.2f',algorithms{m},T.loss(T.algorithmNum==m &  T.dataset==i)));
                end;
                keyboard; 
            end;
        end;
        
        %
    case 'within'
        % ToDO
end

% Recieves predicted and actual as matrices (or vectors)
function loss = evalLoss(actual,prediction,lossfcn)
switch (lossfcn)
    case 'error'
        loss = mean(abs(actual-(prediction>0.5))); % Mean prediction error
    case 'abserror'
        loss = mean(abs(actual-(prediction))); % Mean prediction error
end;